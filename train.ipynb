{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from kaggle_environments import make, evaluate\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(obs, config):\n",
    "    print(config.rows)\n",
    "    print(config.columns)\n",
    "    print(obs[\"board\"])\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = make(\"connectx\", debug=True)\n",
    "test_env.run([test,\"random\"])\n",
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建置openAI GYM的環境\n",
    "class ConnectFourGym(gym.Env):\n",
    "    def __init__(self, agent2=\"random\"):\n",
    "        ks_env = make(\"connectx\", debug=True)\n",
    "        self.env = ks_env.train([None, agent2])\n",
    "        self.rows = ks_env.configuration.rows\n",
    "        self.columns = ks_env.configuration.columns\n",
    "        # Learn about spaces here: http://gym.openai.com/docs/#spaces\n",
    "        self.action_space = spaces.Discrete(self.columns)\n",
    "        self.observation_space = spaces.Box(low=0, high=2, \n",
    "                                            shape=(1,self.rows,self.columns), dtype=int)\n",
    "        # Tuple corresponding to the min and max possible rewards\n",
    "        self.reward_range = (-10, 1)\n",
    "        # StableBaselines throws error if these are not defined\n",
    "        self.spec = None\n",
    "        self.metadata = None\n",
    "    def reset(self):\n",
    "        self.obs = self.env.reset()\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns)\n",
    "    def change_reward(self, old_reward, done):\n",
    "        if old_reward == 1: # The agent won the game\n",
    "            return 1\n",
    "        elif done: # The opponent won the game\n",
    "            return -1\n",
    "        else: # Reward 1/42\n",
    "            return 1/(self.rows*self.columns)\n",
    "    def step(self, action):\n",
    "        # Check if agent's move is valid\n",
    "        is_valid = (self.obs['board'][int(action)] == 0)\n",
    "        if is_valid: # Play the move\n",
    "            self.obs, old_reward, done, _ = self.env.step(int(action))\n",
    "            reward = self.change_reward(old_reward, done)\n",
    "        else: # End the game and penalize agent\n",
    "            reward, done, _ = -10, True, {}\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns), reward, done, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import BaseFeaturesExtractor\n",
    "import torch\n",
    "from torch import nn\n",
    "from tool.check_win import check_win, get_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def opponent(obs, config):\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    for i in range(7):\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=2)):\n",
    "            return i\n",
    "    for i in range(7):\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=1)):\n",
    "            print(i)\n",
    "            return i\n",
    "            \n",
    "\n",
    "    return random.choice(valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class connect_x_policy(BaseFeaturesExtractor): # Custom\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super(connect_x_policy, self).__init__(observation_space, features_dim)\n",
    "        \n",
    "        input_channel = observation_space.shape[0]\n",
    "        self.output_shape = observation_space.shape[1]\n",
    "\n",
    "        # 定义自定义网络\n",
    "        # 假设observation_space是一个向量\n",
    "        self.input_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            n_flatten = self.input_cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "            \n",
    "\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_cnn(observations)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x21f0c0b5b80>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=connect_x_policy)\n",
    "env = ConnectFourGym(agent2=opponent)\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, learning_rate=0.0003, n_steps=2048, n_epochs=10)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = model.policy\n",
    "\n",
    "def use_policy(obs, config):\n",
    "\n",
    "    #將資料整理成輸入格式\n",
    "    board = np.array(obs[\"board\"])\n",
    "    board = board.reshape(1, 1, config.rows, config.columns)\n",
    "    board_tensor = torch.tensor(board)\n",
    "    \n",
    "\n",
    "    board_tensor = board_tensor.to(device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "\n",
    "    predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "\n",
    "    #防止選到不能放棋子的格子\n",
    "    while(board[0, 0, 0, predict] != 0):\n",
    "        predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "    #陽春顯示畫面....\n",
    "    new_board, _ = get_position(board.reshape(config.rows, config.columns), predict, 1)\n",
    "    print(new_board)\n",
    "\n",
    "\n",
    "    return predict\n",
    "\n",
    "def human_play(obs, config):\n",
    "    board = np.array(obs[\"board\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [1 0 2 1 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [1 0 2 1 0 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [1 2 2 1 0 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [2 0 1 0 0 0 1]\n",
      " [1 2 2 1 0 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [2 0 1 0 0 0 1]\n",
      " [1 2 2 1 2 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [2 0 1 1 2 0 1]\n",
      " [1 2 2 1 2 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 2 1 0 1]\n",
      " [2 0 1 1 2 0 1]\n",
      " [1 2 2 1 2 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 1 2 1 0 1]\n",
      " [2 2 1 1 2 0 1]\n",
      " [1 2 2 1 2 0 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 0]\n",
      " [0 0 1 2 1 0 1]\n",
      " [2 2 1 1 2 0 1]\n",
      " [1 2 2 1 2 1 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 2]\n",
      " [0 0 1 2 1 0 1]\n",
      " [2 2 1 1 2 1 1]\n",
      " [1 2 2 1 2 1 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 1 2 0 0 2]\n",
      " [0 2 1 2 1 0 1]\n",
      " [2 2 1 1 2 1 1]\n",
      " [1 2 2 1 2 1 2]]\n"
     ]
    }
   ],
   "source": [
    "test_env = make(\"connectx\", debug=True)\n",
    "test_env.run([use_policy,\"random\"])\n",
    "test_env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
