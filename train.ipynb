{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\AI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import BaseFeaturesExtractor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from kaggle_environments import make, evaluate\n",
    "\n",
    "from tool.check_win import check_win, get_position\n",
    "from tool.check_three import check_three\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env.step\n",
    "回傳值:(obs, reward, done , _)\n",
    "## obs\n",
    "- 只有board有用?\n",
    "## reward\n",
    "- 贏了是1\n",
    "- 平常是0\n",
    "## done\n",
    "- 遊戲是否結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建置openAI GYM的環境\n",
    "#code from: https://www.kaggle.com/code/alexisbcook/deep-reinforcement-learning\n",
    "class ConnectFourGym(gym.Env):\n",
    "    def __init__(self, agent2=\"random\"):\n",
    "        ks_env = make(\"connectx\", debug=True)\n",
    "        self.env = ks_env.train([None, agent2])\n",
    "        self.rows = ks_env.configuration.rows\n",
    "        self.columns = ks_env.configuration.columns\n",
    "        # Learn about spaces here: http://gym.openai.com/docs/#spaces\n",
    "        self.action_space = spaces.Discrete(self.columns)\n",
    "        self.observation_space = spaces.Box(low=0, high=2, \n",
    "                                            shape=(1,self.rows,self.columns), dtype=int)\n",
    "        # Tuple corresponding to the min and max possible rewards\n",
    "        self.reward_range = (-10, 10)\n",
    "        # StableBaselines throws error if these are not defined\n",
    "        self.spec = None\n",
    "        self.metadata = None\n",
    "    def reset(self):\n",
    "        self.obs = self.env.reset()\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns)\n",
    "    def change_reward(self, action : int, old_reward : int, done : bool):\n",
    "        if (done):\n",
    "            if (old_reward == 1): return 10\n",
    "            else: return -10\n",
    "        \n",
    "\n",
    "        board = np.array(self.obs['board'])\n",
    "        board = list(board.reshape(-1))\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        if (check_win(board, self.rows, self.columns, action, 1)): \n",
    "            reward += 10\n",
    "        \n",
    "        #對面差一顆就能連成4的數量\n",
    "        for i in range(7):\n",
    "            if (check_win(board, self.rows, self.columns, i, 2)): \n",
    "                reward -= 0.1\n",
    "\n",
    "                #嘗試阻止對方連線\n",
    "                if (i == action): \n",
    "                    reward += 5\n",
    "        \n",
    "        \n",
    "        #差一顆就能連成4的數量\n",
    "        posible_three = check_three(board, self.rows, self.columns, action, 1)\n",
    "        \n",
    "\n",
    "        if (posible_three >= 1): reward += posible_three * 0.1\n",
    "\n",
    "\n",
    "        return reward\n",
    "            \n",
    "        \n",
    "    def step(self, action):\n",
    "        # Check if agent's move is valid\n",
    "        is_valid = (self.obs['board'][int(action)] == 0)\n",
    "        if is_valid: # Play the move\n",
    "            new_obs, old_reward, done, _ = self.env.step(int(action))\n",
    "            reward = self.change_reward(action, old_reward, done)\n",
    "            self.obs = new_obs\n",
    "\n",
    "\n",
    "        else: # End the game and penalize agent\n",
    "            reward, done, _ = -10, True, {}\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns), reward, done, _\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讓agent更好的抓取圖像特徵\n",
    "class connect_x_policy(BaseFeaturesExtractor): # Custom\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 512):\n",
    "        super(connect_x_policy, self).__init__(observation_space, features_dim)\n",
    "        \n",
    "        input_channel = observation_space.shape[0]\n",
    "        self.output_shape = observation_space.shape[1]\n",
    "\n",
    "        \n",
    "        self.input_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=2, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            n_flatten = self.input_cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "            \n",
    "\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.LeakyReLU())\n",
    "\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_cnn(observations)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def opponent(obs, config):\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    for i in valid_moves:\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=2)):\n",
    "            return i\n",
    "    for i in valid_moves:\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=1)):\n",
    "            return i\n",
    "            \n",
    "\n",
    "    return random.choice(valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\AI\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.78     |\n",
      "|    ep_rew_mean     | -2.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 138      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.81        |\n",
      "|    ep_rew_mean          | -1.87       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773165 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.35        |\n",
      "|    ep_rew_mean          | -1.89       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010061551 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.117      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.537       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 3.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.77        |\n",
      "|    ep_rew_mean          | -1.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009363901 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.114      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.26        |\n",
      "|    ep_rew_mean          | -1.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015416127 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.355      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.308       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.4         |\n",
      "|    ep_rew_mean          | -1.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017872032 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.00959    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.651       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.49        |\n",
      "|    ep_rew_mean          | -1.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023202674 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0503     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 2.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.33        |\n",
      "|    ep_rew_mean          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024978016 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.304      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.545       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.66        |\n",
      "|    ep_rew_mean          | -1.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027265236 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -0.0772     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.479       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 1.68        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.28      |\n",
      "|    ep_rew_mean          | -1.48     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 135       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 151       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0262321 |\n",
      "|    clip_fraction        | 0.291     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.82     |\n",
      "|    explained_variance   | -0.146    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.499     |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -0.0419   |\n",
      "|    value_loss           | 1.61      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.58      |\n",
      "|    ep_rew_mean          | -1.17     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 135       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 166       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0299275 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.81     |\n",
      "|    explained_variance   | -0.127    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.642     |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0423   |\n",
      "|    value_loss           | 1.88      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.17        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034537964 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -0.0917     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.09       |\n",
      "|    ep_rew_mean          | -1.16      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 196        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03675281 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | -0.139     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.184      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0431    |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.15        |\n",
      "|    ep_rew_mean          | -0.816      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034294017 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.292       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.24        |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042299666 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.539      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.235       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 0.807       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.95        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041266397 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.81       |\n",
      "|    ep_rew_mean          | -0.894     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04301868 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.71      |\n",
      "|    explained_variance   | -0.0993    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.245      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 1.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.56        |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052413292 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.436      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00261     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 0.783       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.89        |\n",
      "|    ep_rew_mean          | -1.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040152095 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.062      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.517       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.25        |\n",
      "|    ep_rew_mean          | -1.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041961387 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.965       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.89        |\n",
      "|    ep_rew_mean          | -1.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038809113 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.0916     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.13        |\n",
      "|    ep_rew_mean          | -0.976      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057966262 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.284      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 0.633       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.22        |\n",
      "|    ep_rew_mean          | -0.924      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049722664 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.0261     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.354       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.16        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059633613 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -0.308      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    value_loss           | 0.542       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.87        |\n",
      "|    ep_rew_mean          | -0.803      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050973374 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.0861      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.517       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 0.933       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.66        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074089594 |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.204      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0546      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    value_loss           | 0.488       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.71        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052153174 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.0341     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00471    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.83        |\n",
      "|    ep_rew_mean          | -0.834      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064089015 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -0.123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.412       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.35        |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070099056 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.18       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.809       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.86        |\n",
      "|    ep_rew_mean          | -0.853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071060166 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -0.128      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.289       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 0.544       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.46      |\n",
      "|    ep_rew_mean          | -0.959    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 135       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 469       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0641482 |\n",
      "|    clip_fraction        | 0.448     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.43     |\n",
      "|    explained_variance   | -0.183    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0663    |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.0341   |\n",
      "|    value_loss           | 0.992     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.7         |\n",
      "|    ep_rew_mean          | -0.767      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064716585 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.0774     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.49       |\n",
      "|    ep_rew_mean          | -1.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 500        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06279937 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.0531     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.692      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.53       |\n",
      "|    ep_rew_mean          | -1.22      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 515        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07585807 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | -0.311     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 0.717      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.93        |\n",
      "|    ep_rew_mean          | -1.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055734828 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0238     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.03        |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057557605 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.023      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 0.896       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.78       |\n",
      "|    ep_rew_mean          | -0.915     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 561        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07560322 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | -0.225     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0652    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 0.525      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.54        |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072682574 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.0975      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0621      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.705       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.86        |\n",
      "|    ep_rew_mean          | -0.823      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063803725 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.55       |\n",
      "|    ep_rew_mean          | -0.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10733716 |\n",
      "|    clip_fraction        | 0.486      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | -0.485     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0564    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 0.342      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.22       |\n",
      "|    ep_rew_mean          | -0.864     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 623        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07549635 |\n",
      "|    clip_fraction        | 0.437      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0217    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.492      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.59       |\n",
      "|    ep_rew_mean          | -0.769     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 638        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07004906 |\n",
      "|    clip_fraction        | 0.372      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.0347     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.031     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0354    |\n",
      "|    value_loss           | 0.67       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.43        |\n",
      "|    ep_rew_mean          | -0.909      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.088728815 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.872       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.7         |\n",
      "|    ep_rew_mean          | -0.797      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.073929556 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.53       |\n",
      "|    ep_rew_mean          | -0.901     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 684        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09176548 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | -0.267     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0036     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 0.38       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.98        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069121525 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00475    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.89       |\n",
      "|    ep_rew_mean          | -1.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 715        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07509446 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.13       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.359      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.62       |\n",
      "|    ep_rew_mean          | -0.659     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 730        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08047936 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.0261     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0106     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    value_loss           | 0.733      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 8.69      |\n",
      "|    ep_rew_mean          | -0.627    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 745       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0979017 |\n",
      "|    clip_fraction        | 0.409     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | -0.133    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0903    |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.0414   |\n",
      "|    value_loss           | 0.614     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x186735dc910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=connect_x_policy)\n",
    "env = ConnectFourGym(agent2=opponent)\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, learning_rate=0.0003, n_steps=2048, n_epochs=10, verbose=1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = model.policy\n",
    "\n",
    "def use_policy(obs, config):\n",
    "\n",
    "    \n",
    "\n",
    "    #將資料整理成輸入格式\n",
    "    board = np.array(obs[\"board\"])\n",
    "    board = board.reshape(1, 1, config.rows, config.columns)\n",
    "    board_tensor = torch.tensor(board)\n",
    "    \n",
    "\n",
    "    board_tensor = board_tensor.to(device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "\n",
    "    predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "\n",
    "    #防止選到不能放棋子的格子\n",
    "    while(board[0, 0, 0, predict] != 0):\n",
    "        predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "    #陽春顯示畫面....\n",
    "    new_board, _ = get_position(board.reshape(config.rows, config.columns), predict, 1)\n",
    "    print(new_board)\n",
    "    \n",
    "    win = check_win(list(board), config.rows, config.columns, predict, 1)\n",
    "    print(win)\n",
    "    return predict\n",
    "\n",
    "def human_play(obs, config):\n",
    "    board = np.array(obs[\"board\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_percentages(agent1, agent2, n_rounds=100):\n",
    "    # Use default Connect Four setup\n",
    "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
    "    # Agent 1 goes first (roughly) half the time          \n",
    "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
    "    # Agent 2 goes first (roughly) half the time      \n",
    "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
    "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
    "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
    "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
    "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 Win Percentage: 0.13\n",
      "Agent 2 Win Percentage: 0.87\n",
      "Number of Invalid Plays by Agent 1: 0\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(use_policy, opponent, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"connect_x_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
