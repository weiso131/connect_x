{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\AI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import BaseFeaturesExtractor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from kaggle_environments import make, evaluate\n",
    "\n",
    "from tool.check_win import check_win, get_position\n",
    "from tool.check_three import check_three\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env.step\n",
    "回傳值:(obs, reward, done , _)\n",
    "## obs\n",
    "- 只有board有用?\n",
    "## reward\n",
    "- 贏了是1\n",
    "- 平常是0\n",
    "## done\n",
    "- 遊戲是否結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建置openAI GYM的環境\n",
    "#code from: https://www.kaggle.com/code/alexisbcook/deep-reinforcement-learning\n",
    "class ConnectFourGym(gym.Env):\n",
    "    def __init__(self, agent2=\"random\"):\n",
    "        ks_env = make(\"connectx\", debug=True)\n",
    "        self.env = ks_env.train([None, agent2])\n",
    "        self.rows = ks_env.configuration.rows\n",
    "        self.columns = ks_env.configuration.columns\n",
    "        # Learn about spaces here: http://gym.openai.com/docs/#spaces\n",
    "        self.action_space = spaces.Discrete(self.columns)\n",
    "        self.observation_space = spaces.Box(low=0, high=2, \n",
    "                                            shape=(1,self.rows,self.columns), dtype=int)\n",
    "        # Tuple corresponding to the min and max possible rewards\n",
    "        self.reward_range = (-10, 10)\n",
    "        # StableBaselines throws error if these are not defined\n",
    "        self.spec = None\n",
    "        self.metadata = None\n",
    "    def reset(self):\n",
    "        self.obs = self.env.reset()\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns)\n",
    "    def change_reward(self, action : int, old_reward : int, done : bool):\n",
    "        if (done):\n",
    "            if (old_reward == 1): return 10\n",
    "            else: return -10\n",
    "        \n",
    "\n",
    "        board = np.array(self.obs['board'])\n",
    "        board = list(board.reshape(-1))\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        if (check_win(board, self.rows, self.columns, action, 1)): \n",
    "            reward += 10\n",
    "        \n",
    "        #對面差一顆就能連成4的數量\n",
    "        for i in range(7):\n",
    "            if (check_win(board, self.rows, self.columns, i, 2)): \n",
    "                reward -= 3\n",
    "\n",
    "                #嘗試阻止對方連線\n",
    "                if (i == action): \n",
    "                    reward += 5\n",
    "        \n",
    "        \n",
    "        #差一顆就能連成4的數量\n",
    "        posible_three = check_three(board, self.rows, self.columns, action, 1)\n",
    "        \n",
    "\n",
    "        if (posible_three >= 1): reward += posible_three * 0.5\n",
    "\n",
    "\n",
    "        return reward\n",
    "            \n",
    "        \n",
    "    def step(self, action):\n",
    "        # Check if agent's move is valid\n",
    "        is_valid = (self.obs['board'][int(action)] == 0)\n",
    "        if is_valid: # Play the move\n",
    "            new_obs, old_reward, done, _ = self.env.step(int(action))\n",
    "            reward = self.change_reward(action, old_reward, done)\n",
    "            self.obs = new_obs\n",
    "\n",
    "\n",
    "        else: # End the game and penalize agent\n",
    "            reward, done, _ = -10, True, {}\n",
    "        return np.array(self.obs['board']).reshape(1,self.rows,self.columns), reward, done, _\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讓agent更好的抓取圖像特徵\n",
    "class connect_x_policy(BaseFeaturesExtractor): # Custom\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super(connect_x_policy, self).__init__(observation_space, features_dim)\n",
    "        \n",
    "        input_channel = observation_space.shape[0]\n",
    "        self.output_shape = observation_space.shape[1]\n",
    "\n",
    "        \n",
    "        self.input_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Flatten())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            n_flatten = self.input_cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "            \n",
    "\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.LeakyReLU())\n",
    "\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_cnn(observations)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def opponent(obs, config):\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    for i in valid_moves:\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=2)):\n",
    "            return i\n",
    "    for i in valid_moves:\n",
    "        if (check_win(board=obs.board, row=config.rows, col=config.columns, choice=i, player=1)):\n",
    "            return i\n",
    "            \n",
    "\n",
    "    return random.choice(valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\AI\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.74     |\n",
      "|    ep_rew_mean     | -8.45    |\n",
      "| time/              |          |\n",
      "|    fps             | 136      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.68        |\n",
      "|    ep_rew_mean          | -8.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011731161 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.02        |\n",
      "|    ep_rew_mean          | -8.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010499099 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.202      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.743       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 6.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.25        |\n",
      "|    ep_rew_mean          | -7.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012238966 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0597     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 9.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.2         |\n",
      "|    ep_rew_mean          | -7.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010737855 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.0941     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.43        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.59        |\n",
      "|    ep_rew_mean          | -7.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007959131 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -0.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.18        |\n",
      "|    ep_rew_mean          | -8.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010693979 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.11        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.19        |\n",
      "|    ep_rew_mean          | -7.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007469762 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.0276     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.66        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.67        |\n",
      "|    ep_rew_mean          | -7.73       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010747745 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.0579     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.46        |\n",
      "|    ep_rew_mean          | -6.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012120844 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0684     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 9.77        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.2        |\n",
      "|    ep_rew_mean          | -6.92      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01433939 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | -0.0853    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.62       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 15.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.1         |\n",
      "|    ep_rew_mean          | -6.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011956224 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.0835     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.33         |\n",
      "|    ep_rew_mean          | -6.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126811275 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | -0.0485      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.11         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.37        |\n",
      "|    ep_rew_mean          | -6.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016631955 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -0.177      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.78        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.94        |\n",
      "|    ep_rew_mean          | -5.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017695967 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0415     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.88        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.7        |\n",
      "|    ep_rew_mean          | -3.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 242        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01514838 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | -0.0469    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.93        |\n",
      "|    ep_rew_mean          | -5.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013350103 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.059      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.35        |\n",
      "|    ep_rew_mean          | -6.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017512586 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.0927     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.99        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.08        |\n",
      "|    ep_rew_mean          | -4.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020202972 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.12        |\n",
      "|    ep_rew_mean          | -4.55       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020146113 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.0792     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.61        |\n",
      "|    ep_rew_mean          | -5.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019663122 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.12        |\n",
      "|    ep_rew_mean          | -3.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023652587 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.117      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.43        |\n",
      "|    ep_rew_mean          | -2.92       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023020688 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -0.0826     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.88        |\n",
      "|    ep_rew_mean          | -2.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022787672 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.18        |\n",
      "|    ep_rew_mean          | -1.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028319668 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.3         |\n",
      "|    ep_rew_mean          | -3.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022019224 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.29      |\n",
      "|    ep_rew_mean          | -4.56     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 410       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0248987 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | 0.0307    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8         |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    value_loss           | 33.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.3         |\n",
      "|    ep_rew_mean          | -4.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026407955 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.67        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.88        |\n",
      "|    ep_rew_mean          | -2.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026126765 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.32        |\n",
      "|    ep_rew_mean          | -0.49       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022242509 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.0551      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.39        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028909713 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.948      |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76        |\n",
      "|    ep_rew_mean          | -3.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035368696 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 0.0564      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.3         |\n",
      "|    ep_rew_mean          | -0.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030120613 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.95        |\n",
      "|    ep_rew_mean          | -1.57       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035450302 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.17      |\n",
      "|    ep_rew_mean          | -1.17     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 532       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0384754 |\n",
      "|    clip_fraction        | 0.233     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.852    |\n",
      "|    explained_variance   | 0.117     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 12.2      |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.0217   |\n",
      "|    value_loss           | 36.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.59        |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033544566 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.0942      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.52        |\n",
      "|    ep_rew_mean          | -2.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037939392 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.26      |\n",
      "|    ep_rew_mean          | -1.04     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 134       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 579       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0412193 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.777    |\n",
      "|    explained_variance   | 0.0457    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 13.5      |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -0.0164   |\n",
      "|    value_loss           | 40.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.08        |\n",
      "|    ep_rew_mean          | -2.83       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040958516 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.38       |\n",
      "|    ep_rew_mean          | -1.21      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 610        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04540892 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.767     |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24         |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 36.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.31        |\n",
      "|    ep_rew_mean          | -1.92       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045316402 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.44       |\n",
      "|    ep_rew_mean          | -2.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 640        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03692653 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.702     |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    value_loss           | 39.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.09        |\n",
      "|    ep_rew_mean          | -0.235      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044055723 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.4         |\n",
      "|    ep_rew_mean          | 0.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042189706 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.09        |\n",
      "|    ep_rew_mean          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038514778 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.15        |\n",
      "|    ep_rew_mean          | 0.765       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 701         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053711597 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.14       |\n",
      "|    ep_rew_mean          | 1.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 716        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04398466 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.673     |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 35.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | 0.335       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049094304 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.97       |\n",
      "|    ep_rew_mean          | 1.93       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 747        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04709127 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.617     |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    value_loss           | 38.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x24a6ed207c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=connect_x_policy)\n",
    "env = ConnectFourGym(agent2=opponent)\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, learning_rate=0.0003, n_steps=2048, n_epochs=10, verbose=1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = model.policy\n",
    "\n",
    "def use_policy(obs, config):\n",
    "\n",
    "    \n",
    "\n",
    "    #將資料整理成輸入格式\n",
    "    board = np.array(obs[\"board\"])\n",
    "    board = board.reshape(1, 1, config.rows, config.columns)\n",
    "    board_tensor = torch.tensor(board)\n",
    "    \n",
    "\n",
    "    board_tensor = board_tensor.to(device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "\n",
    "    predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "\n",
    "    #防止選到不能放棋子的格子\n",
    "    while(board[0, 0, 0, predict] != 0):\n",
    "        predict = int(policy.forward(board_tensor)[0])\n",
    "\n",
    "    #陽春顯示畫面....\n",
    "    new_board, _ = get_position(board.reshape(config.rows, config.columns), predict, 1)\n",
    "    print(new_board)\n",
    "    \n",
    "    win = check_win(list(board), config.rows, config.columns, predict, 1)\n",
    "    print(win)\n",
    "    return predict\n",
    "\n",
    "def human_play(obs, config):\n",
    "    board = np.array(obs[\"board\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_percentages(agent1, agent2, n_rounds=100):\n",
    "    # Use default Connect Four setup\n",
    "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
    "    # Agent 1 goes first (roughly) half the time          \n",
    "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
    "    # Agent 2 goes first (roughly) half the time      \n",
    "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
    "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
    "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
    "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
    "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 Win Percentage: 0.37\n",
      "Agent 2 Win Percentage: 0.62\n",
      "Number of Invalid Plays by Agent 1: 0\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(use_policy, opponent, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"connect_x_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
